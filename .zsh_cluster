#!/bin/zsh
#================================================================
#- IMPLEMENTATION
#-    version         0.0.5
#-    author          Maximilian Oppelt
#-
#================================================================
#  HISTORY
#     2021/01/01 : Maximilian Oppelt : File created.
#     2021/02/11 : Maximilian Oppelt : Add script name as option
#     2021/12/14 : Maximilian Oppelt : Bug fix in project name and Update docker image
#     2021/12/23 : Maximilian Oppelt : New custom image for faster startup
#     2021/12/24 : Maximilian Oppelt : The cluster script will be deprecated 01/2022
#                                      Added initial version for new interface.
#     2022/01/20 : Maximilian Oppelt : Increased shared memory for pytorch dataloader.
#
#================================================================

function dli() {
    local name=""
    if [[ "${1}" ]]; then
        name="${1}"
        # name="${job_name//-master-0/}"
    else
        echo "ERROR: No job name provided."
        return 1
    fi
    kubectl describe pod $name
}

function dlh()
{
    echo "# ===================================================================="
    echo "#  COLLECTION OF LAZY DEEP LEARNER CLUSTER SCRIPT"
    echo "# ===================================================================="
    echo "# These functions simplify the managment (starting/stopping/observing)"
    echo "# of deep learning jobs on the SSE deep learning cluster."
    echo "#"
    echo "#  USAGE"
    echo "# ===================================================================="
    echo "#\tCreating a new job:       \tdlr <SCRIPT>"
    echo "#\tPrinting log of job:      \tdll <JOBNAME>"
    echo "#\tDeleting (old) jobs:      \tdld <JOBNAME>"
    echo "#\tObserving current jobs:   \tdls"
    echo "#\tRemove all jobs:          \tdla"
    echo "# ===================================================================="
} 


function dll() {
    local name=""
    local watch=0
    while [[ $# -gt 0 ]]; do
    case "$1" in
        -w)
            watch=1
            ;;
        *)
            name="${1}"
        ;;
    esac
    shift
    done
    if ! [[ $name ]]; then
        echo "ERROR: No job name provided."
        return 1
    fi
    
    if [[ $watch ]]; then
        kubectl logs -f $name
    else
        kubectl logs $name
    fi
}

function dlda() {
    echo "Are you sure? Do you want to delete these jobs:"
    kubectl get pods -o wide
    select yn in "Yes" "No"; do
    case $yn in
        Yes ) kubectl delete --all pods ; return ;;
        No ) return ;;
    esac
    done
}

function dld() {
    local name=""
    if [[ "${1}" ]]; then
        name="${1}"
        # name="${job_name//-master-0/}"
    else
        echo "ERROR: No job name provided."
        return 1
    fi
    kubectl delete Pod $name
}

function dls() {
    watch=0 
    while [[ $# -gt 0 ]]; do
    case "$1" in
        -w)
            watch=1
            ;;
    esac
    shift
    done
    
    # Show all running kubectl jobs (either once or live)
    if [[ "$watch" = 1 ]]; then
        echo "INFO: Interrupt with Ctrl+C."
        kubectl get pods -w -o wide
    else
        kubectl get pods -o wide
    fi
}

function dlr() {
    # Create manifest file, Sync 
    # For the new compute cluster the interface changed.
    local dl_user=$USER
    local dl_host=dlcluster1scratch.iis.fhg.de
    local dl_name=""

    local dl_nodes=1
    local dl_gpus=1
    local dl_cpus=6
    local dl_memory=12G

    local dl_image=maxoppelt/pytorch:cuda-11.3-cudnn8-devel-pytorch1.10-custom
    local dl_accelerator=nvidia-tesla-p100
    local dl_script=run.sh

    while [[ $# -gt 0 ]]; do
    case "$1" in
        --user*|-u*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_user="${1#*=}"
            ;;

        --host*|-s*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_host="${1#*=}"
            ;;

        --nodes*|-n*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_nodes="${1#*=}"
            ;;

        --gpus*|-g*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_gpus="${1#*=}"
            ;;

        --cpus*|-c*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_cpus="${1#*=}"
            ;;

        --memory*|-m*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_memory="${1#*=}"
            ;;

        --image*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_image="${1#*=}"
            ;;

        --accelerator*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_accelerator="${1#*=}"
            ;;

        --script*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_script="${1#*=}"
            ;;
        *)
            dl_script="${1}"
        ;;
 
    esac
    shift
    done

    local dl_scope_home="/scratch/home/$dl_user"
    local dl_scope_data="/scratch/scratch/data/$dl_user"
    local dl_scope_output="/scratch/scratch/output/$dl_user"

    local container_scope_home="/home/$dl_user"
    local container_scope_data="/data/$dl_user"
    local container_scope_output="/output/$dl_user"

    local dl_project=${PWD##*/}
    local dl_name="$dl_project"-"$(date -u +"%Y-%m-%d-%H-%M-%S")"

    local dl_scope_project=$dl_scope_home/projects/$dl_name/
    local container_scope_project=$container_scope_home/projects/$dl_name

    local dl_uid=$(ssh $dl_user@$dl_host 'id -u $dl_user')
    local dl_gid=$(ssh $dl_user@$dl_host 'id -g $dl_user')
    ssh $dl_user@$dl_host "ln -sf $dl_scope_data data; ln -sf $dl_scope_output output; mkdir -p $dl_scope_home/projects"
    
    echo "Creating manifest with configuration: "
    echo "==================================================================="
    echo "USER: $dl_user [UID: $dl_uid / GID: $dl_gid]"
    echo "NAM: $dl_name"
    echo "MOUNTS:"
    echo "  - $dl_scope_home -> $container_scope_home"
    echo "  - $dl_scope_data -> $container_scope_data"
    echo "  - $dl_scope_output -> $container_scope_output"
    echo "HOST: $dl_host"
    echo "NODES: $dl_nodes"
    echo "CPUS: $dl_cpus"
    echo "GPUS: $dl_gpus"
    echo "MEMORY: $dl_memory"
    echo "SCRIPT: $container_scope_home/projects/$dl_name/$dl_script"
    echo "==================================================================="

    # Syncing local project to deep learning cluster
    local git_repo="$(git rev-parse --is-inside-work-tree 2>/dev/null)"
    if [[ "$git_repo" ]]; then
        if [[ $(git rev-parse --show-toplevel) != $(pwd) ]]; then
            echo "ERROR: Not in git root directory"
            return 1
        fi
    else
        echo "ERROR: Folder is no git repository. Stop syncing..."
        return 1
    fi
    echo "INFO: Synced ${PWD} to $dl_user"@"$dl_host:$dl_scope_home/projects/$dl_name"
    rsync --exclude '.git' \
          --exclude 'logs/' \
          --exclude '__pycache__' \
          -av --delete \
          -e ssh ${PWD}/ $dl_user@$dl_host:$dl_scope_home/projects/$dl_name

    # Create/Build kubectl manifest file
    if [[ $dl_nodes == 1 ]]; then
    local manifest="---
apiVersion: v1
kind: Pod
metadata:
  name: $dl_name
spec:
  restartPolicy: Never
  containers:
  - name: dl-gpu-job
    image: $dl_image
    command:
    - sh
    - -c
    args:
    - export name=$dl_nodes ; 
      export cpus=$dl_nodes ; 
      export nodes=$dl_nodes ;
      export home_path=$container_scope_home ;
      export data_path=$container_scope_data ;
      export output_path=$container_scope_output ;
      export project_path=$container_scope_project ;
      chown -R $dl_uid:$dl_gid $container_scope_output ;
      apt-get -y update ;
      /bin/sh $container_scope_project/$dl_script ;
      chown -R $dl_uid:$dl_gid $container_scope_output ;
    resources:
      requests:
        cpu: $dl_cpus
        memory: $dl_memory
      limits:
        cpu: $dl_cpus
        memory: $dl_memory 
        nvidia.com/gpu: $dl_gpus
    securityContext:
      allowPrivilegeEscalation: false    
    volumeMounts:
    - name: nfs-output
      mountPath: $container_scope_output
    - name: nfs-data
      mountPath: $container_scope_data
    - name: nfs-home
      mountPath: $container_scope_home
    - mountPath: /dev/shm
      name: dshm
  volumes:
  - name: nfs-output
    nfs:
      server: 10.54.182.12
      path: $dl_scope_output
      readOnly: false
  - name: nfs-data
    nfs:
      server: 10.54.182.12
      path: $dl_scope_data
      readOnly: true
  - name: nfs-home
    nfs:
      server: 10.54.182.12
      path: $dl_scope_home
      readOnly: true
  - name: dshm
    emptyDir:
      medium: Memory
    "
    else

    fi
    
    echo $manifest | kubectl create -f -
}


function cluster_help()
{
    echo "# ===================================================================="
    echo "#  THE LAZY DEEP LEARNER CLUSTER SCRIPT - NOTE: CLUSTER IS DEPRECATED"
    echo "# ===================================================================="
    echo "# This function simplifies the managment (starting/stopping/observing)"
    echo "# of deep learning jobs on the SSE deep learning cluster."
    echo "#"
    echo "#  USAGE"
    echo "# ===================================================================="
    echo "#\tCreating a new job:       \tcluster run <JOBNAME>"
    echo "#\tObserving current jobs:   \tcluster jobs"
    echo "#\tPrinting log of job:      \tcluster log <JOBNAME>"
    echo "#\tCleaning (old) runs:      \tcluster clean"
    echo "#\tDeleting (old) jobs:      \tcluster delete <JOBNAME>"
    echo "#\tSynchronize outputs:      \tcluster sync"
    echo "#\tMonitor cluster usage:    \tcluster monitor"
    echo "#\tInit cluster environment: \tcluster init"
    echo "#"
    echo "# PARAMETERS"
    echo "# ===================================================================="
    echo "# cluster --dl_user <USERSHORT>"
    echo "#         --dl_host <SERVER>"
    echo "#         --dl_nodes <#NODES>"
    echo "#         --dl_gpus <#GPUS>"
    echo "#         --dl_cpus <#CPUS>"
    echo "#         --dl_memory <MEMSIZE>Mi"
    echo "#         --dl_image <DOCKERHUB>"
    echo "#         -w"
    echo "#         jobs"
    echo "# --dl_user       \t-u <USERSHORT> is the username on the cluster. If not set the local user name is used."
    echo "# --dl_host        \t-s The name of the remote cluster. [Default: dlcluster1head]"
    echo "# --dl_nodes       \t-s Number of Nodes. [Default: 1]"
    echo "# --dl_gpus        \t-g Number of GPUs. [Default: 1]"
    echo "# --dl_cpus        \t-c Number of CPUs. [Default: 6]"
    echo "# --dl_memory      \t-c Memory size. [Default: 12G]"
    echo "# --dl_script      \t-c Deep Learning Script. [Default: run.sh]"
    echo "# --dl_accelerator \t-a GPU accelerator type. [Default: nvidia-tesla-p100] (Available: nvidia-tesla-p40)"
    echo "# --dl_image       \t-i Docker image used for container creation. [Default: maxoppelt/pytorch:cuda-11.3-cudnn8-devel-pytorch1.10-custom]"
    echo "#                  \t-w Enables live view."
    echo "#                  \t-h Prints this help."
    echo "# ===================================================================="
}

function cluster()
{
    echo "The support using the kubectl control using a headnode is deprecated."
    # Login information for the cluster
    local dl_user=$USER
    local dl_host=dlcluster1head

    # The kubernetes manifest defaults
    local dl_nodes=1
    local dl_ngpus=1
    local dl_ncpus=6
    local dl_memory=12G

    local dl_image=maxoppelt/pytorch:cuda-11.3-cudnn8-devel-pytorch1.10-custom
    local dl_accelerator=nvidia-tesla-p100
    local dl_script=run.sh

    local dl_watch=0

    local do_init=0
    local do_run=0
    local do_log=0
    local do_jobs=0
    local do_clear=0
    local do_delete=0
    local do_sync=0
    local do_monitor=0
    local do_describe=0

    local ssh_connection=0

    while [[ $# -gt 0 ]]; do
    case "$1" in
        --dl_user*|-u*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_user="${1#*=}"
            ;;

        --dl_host*|-s*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_host="${1#*=}"
            ;;

        --dl_nodes*|-n*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_nodes="${1#*=}"
            ;;

        --dl_gpus*|-g*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_ngpus="${1#*=}"
            ;;

        --dl_cpus*|-c*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_ncpus="${1#*=}"
            ;;

        --dl_memory*|-m*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_memory="${1#*=}"
            ;;

        --dl_image*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_image="${1#*=}"
            ;;

        --dl_accelerator*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_accelerator="${1#*=}"
            ;;

        --dl_script*|-i*)
            if [[ "$1" != *=* ]]; then shift; fi
                local dl_script="${1#*=}"
            ;;

        -w)
            dl_watch=1
            ;;

        init)
            do_init=1
            ;;

        jobs)
            do_jobs=1
            ;;

        clean)
            do_clear=1
            ;;

        sync)
            do_sync=1
            ;;
 
        log*)
            if [[ "$1" != *=* ]]; then shift; fi
                if [[ "${1#*=}" ]]; then
                    job_name="${1#*=}"
                else
                    echo "ERROR: No job name provided."
                    return 1
                fi
                do_log=1
            ;;

        describe*)
            if [[ "$1" != *=* ]]; then shift; fi
                if [[ "${1#*=}" ]]; then
                    job_name="${1#*=}"
                else
                    echo "ERROR: No job name provided."
                    return 1
                fi
                do_describe=1
            ;;

        delete)
            if [[ "$1" != *=* ]]; then shift; fi
                if [[ "${1#*=}" ]]; then
                    job_name="${1#*=}"
                    # Remove suffix automatically
                    job_name="${job_name//-master-0/}"
                else
                    echo "ERROR: No job name provided."
                    return 1
                fi
                do_delete=1
            ;;
 
        run)
            if [[ "$1" != *=* ]]; then shift; fi
                if [[ "${1#*=}" ]]; then
                    job_name="${1#*=}"
                    echo "INFO: Running $job_name"
                else
                    echo "ERROR: No job name provided."
                    return 1
                fi
                do_run=1
            ;;

        monitor)
            do_monitor=1
            ;;

        -h)
            cluster_help
            return 1
            ;;
        *)
            >&2 printf "ERROR: Invalid argument\n"
            cluster_help
            return 1
        ;;
    esac
    shift
    done

    # Current folder name
    local project_name=${PWD##*/}
    # local project_name="${project_name//_/-}"

    # General Information Cluster container scope
    # NAME:     CLUSTER SCOPE                 CONTAINER SCOPE
    # data:     /scratch/data/<USERSHORT>     /data/<USERSHORT>
    # output:   /scratch/output/<USERSHORT>   /output/
    # home:     /home/<USERSHORT>             /home/<USERSHORT>

    local dl_home_directory="/home/$dl_user"
    local dl_project_directory="$dl_home_directory/projects"

    local dl_date="$(date -u +"%Y-%m-%d-%H-%M-%S")"
    local dl_job_name="$project_name"-"$dl_date"-"$job_name"
    local dl_job_name="${dl_job_name//_/-}"
    local dl_project_name=$dl_project_directory/$dl_job_name
    local dl_manifest_script="$dl_project_directory/$dl_job_name/run.yml"
    local dl_runner_script="$dl_project_directory/$dl_job_name/$project_name/$dl_script"

    # Define variables in container scope
    local container_project_dir="/home/$dl_user/projects/$dl_job_name/$project_name"
    local container_output_dir="/output"
    local container_input_dir="/data/"$dl_user

    # The local project defaults
    local local_project=${PWD}

    # Initilize the cluster environment
    if [[ "$do_init" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi
        local local_ssh_directory="$HOME/.ssh"

        # Generate rsa files if it does not exist
        if [[ -f $local_ssh_file/id_rsa ]]
        then
            echo "INFO: RSA key exists on $local_ssh_directory/id_rsa, using existing file"
        else
            ssh-keygen -t rsa -f "$local_ssh_directory/id_rsa"
            echo INFO: RSA key pair generated
        fi

        echo "We need to log into $dl_host as $dl_user to set up your public key."
        cat "$local_ssh_directory/id_rsa.pub" | ssh "$dl_host" -l "$dl_user" ' [ -d ~/.ssh ] || \
                                                                    mkdir -p ~/.ssh ; \
                                                                    cat > ~/.ssh/KEY ; \
                                                                    KEY=$(cat ~/.ssh/KEY) ; \
                                                                    export KEY ; \
                                                                    grep -q "$KEY" ~/.ssh/authorized_keys || \
                                                                    cat ~/.ssh/KEY >> .ssh/authorized_keys ; \
                                                                    chmod 700 ~/.ssh ; \
                                                                    chmod 600 ~/.ssh/authorized_keys ;
                                                                    rm ~/.ssh/KEY'
        id_rsa_transfer_status=$?

        if [[ $id_rsa_transfer_status -eq 0 ]]; then
            echo "INFO: SSH set up complete: [HOST: $dl_host]"
        else
            echo "ERROR: SSH setup failed."
            return 1
        fi

        # Create project directory
        ssh $dl_user@$dl_host 'mkdir projects'
        ssh $dl_user@$dl_host 'touch .hushlogin'
        ssh $dl_user@$dl_host "ln -s /scratch/data/$dl_user/ data"
        ssh $dl_user@$dl_host "ln -s /scratch/output/$dl_user/ output"
        return 0
    fi

    # Check if ssh status can be established
    local dlssh_status=$(ssh -o BatchMode=yes -o ConnectTimeout=5 $dl_user@$dl_host echo ok 2>&1)
    if [[ $dlssh_status == ok ]]; then
        echo "INFO: Authentification using ssh valid."
    elif [[ $dlssh_status == "Permission denied"* ]]; then
        echo "ERROR: Authentification using ssh invalid: Permission denied."
        return 1
    else
        echo "ERROR: Unknown Error during ssh login."
        return 1
    fi

    # Get uid and group id
    dl_uid=$(ssh $dl_user@$dl_host 'id -u $dl_user')
    dl_gid=$(ssh $dl_user@$dl_host 'id -g $dl_user')

    # Show current jobs
    if [[ "$do_jobs" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        # Show all running kubectl jobs (either once or live)
        if [[ "$dl_watch" = 1 ]]; then
            echo "INFO: Interrupt with Ctrl+C."
            ssh $dl_user@$dl_host 'kubectl get pods -w'
        else
            ssh $dl_user@$dl_host 'kubectl get pods -o wide'
        fi
        return 0
    fi

    # Show log of worker
    if [[ "$do_log" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]] || [[ -z "$job_name" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        # Show log files (either once or live)
        if [[ "$dl_watch" = 1 ]]; then
            echo "INFO: Interrupt with Ctrl+C."
            local kubectl_logs="kubectl logs $job_name --follow"
            echo "$kubectl_logs" | ssh $dl_user@$dl_host -T
        else
            local kubectl_logs="kubectl logs $job_name"
            echo "$kubectl_logs" | ssh $dl_user@$dl_host -T
        fi
        return 0
    fi

    # Describe pod
    if [[ "$do_describe" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]] || [[ -z "$job_name" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        # Show log files (either once or live)
        local kubectl_describe="kubectl describe pod $job_name"
        echo "$kubectl_describe" | ssh $dl_user@$dl_host -T
        return 0
    fi

    # Delete worker
    if [[ "$do_delete" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_ngpus" ]] || [[ -z "$job_name" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        echo "INFO: Deleting $job_name"
        local kubectl_logs="kubectl delete PyTorchJob $job_name"
        echo "$kubectl_logs" | ssh $dl_user@$dl_host -T
        return 0
    fi

    # Clear old manifest files
    if [[ "$do_clear" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_ngpus" ]] || [[ -z "$dl_ncpus" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi
        ssh $dl_user@$dl_host "rm -R $dl_project_directory/*"
        echo "INFO: Cleaned up projects."
        return 0
    fi
    local kubectl_manifest="apiVersion: kubeflow.org/v1beta2
kind: PyTorchJob
metadata:
  name: $dl_job_name
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      ttlSecondsAfterFinished: 60
      template:
        metadata:
          creationTimestamp: null
        spec:
          containers:
            - name: pytorch
              image: $dl_image
              command: [\"/bin/bash\",\"-c\"]
              args:
              - source /root/.bashrc ; export nodes=$dl_nodes ; export experiment=$dl_job_name ; export ngpus=$dl_ngpus ; export uid=$dl_uid ; export gid=$dl_gid ; export project_dir=$container_project_dir ; export output_dir=$container_output_dir ; export input_dir=$container_input_dir ; /bin/bash $dl_runner_script ;
              resources:
                limits:
                  nvidia.com/gpu: $dl_ngpus
                  cpu: $dl_ncpus
                  memory: $dl_memory
              volumeMounts:
              - mountPath: /data/$dl_user
                name: nfs-data
              - mountPath: /output
                name: nfs-output
              - mountPath: /home/$dl_user
                name: nfs-home
              - mountPath: /dev/shm
                name: dshm
          nodeSelector:
            accelerator: $dl_accelerator
          volumes:
          - name: nfs-data
            persistentVolumeClaim:
              claimName: kflow-$dl_user-data-pvc
          - name: nfs-output
            persistentVolumeClaim:
              claimName: kflow-$dl_user-output-pvc
          - name: nfs-home
            persistentVolumeClaim:
              claimName: kflow-$dl_user-home-pvc
          - name: dshm
            emptyDir:
              medium: Memory
";

    # Taining on multiple workers (e.g. using pytorch distributed data parallel)
    if [[ "$dl_nodes" -gt 1 ]]; then
        echo "Training on $dl_nodes nodes using each $dl_ngpus gpus"
local kubectl_manifest=$kubectl_manifest"    Worker:
      replicas: "$((dl_nodes-1))"
      restartPolicy: Never
      template:
        metadata:
          creationTimestamp: null
        spec:
          TTLAfterFinished: 60
          containers:
          - args:
             - source /root/.bashrc ; export nodes=$dl_nodes ; export experiment=$dl_job_name ; export ngpus=$dl_ngpus ; export uid=$dl_uid ; export gid=$dl_gid ; export project_dir=$container_project_dir ; export output_dir=$container_output_dir ; export input_dir=$container_input_dir ; /bin/bash $dl_runner_script ;
            command: [\"/bin/bash\",\"-c\"]
            image: $dl_image
            name: pytorch
            resources:
              limits:
                nvidia.com/gpu: $dl_ngpus
                cpu: $dl_ncpus
                memory: $dl_memory
            volumeMounts:
            - mountPath: /data/$dl_user
              name: nfs-data
            - mountPath: /output
              name: nfs-output
            - mountPath: /home/$dl_user
              name: nfs-home
            - mountPath: /dev/shm
              name: dshm
          nodeSelector:
            accelerator: $dl_accelerator
          restartPolicy: OnFailure
          ttlSecondsAfterFinishing: 1
          volumes:
          - name: nfs-data
            persistentVolumeClaim:
              claimName: kflow-$dl_user-data-pvc
          - name: nfs-output
            persistentVolumeClaim:
              claimName: kflow-$dl_user-output-pvc
          - name: nfs-home
            persistentVolumeClaim:
              claimName: kflow-$dl_user-home-pvc
          - name: dshm
            emptyDir:
              medium: Memory
";
    else
        echo "Training on single node uinsg $dl_ngpus"
    fi

    # Copy project files, write a manifest, create a kubectl job
    if [[ "$do_run" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_ngpus" ]] || [[ -z "$dl_ncpus" ]] || [[ -z "$dl_project_name" ]]; then
            echo "ERROR: Some or all of the parameters are empty"
            cluster_help
            return 1
        fi
        # Check for git repositories
        local git_repo="$(git rev-parse --is-inside-work-tree 2>/dev/null)"
        if [[ "$git_repo" ]]; then
            if [[ $(git rev-parse --show-toplevel) != $(pwd) ]]; then
                echo "ERROR: Not in git root directory"
                return 1
            fi
        else
            echo "WARNING: Folder is no git repository"
        fi
        # Syncing local project to deep learning cluster
        echo "INFO: Synced $local_project to $dl_user"@"$dl_host:$dl_project_name"
        rsync --exclude '.git' --exclude 'logs/' --exclude '__pycache__' -av --delete -e ssh $local_project $dl_user@$dl_host:$dl_project_name/

        echo "INFO: Cluster user has [UID:GID]: $dl_uid:$dl_gid"

        # Write manifest to remote location
        echo "$kubectl_manifest" | ssh $dl_user@$dl_host -T "cat > $dl_manifest_script"
        echo "INFO: Created manifest $manifest_name"

        # Create kubectl job
        ssh $dl_user@$dl_host "kubectl create -f $dl_manifest_script"
        return 0
    fi

    # Synchronize the output directory
    if [[ "$do_sync" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        echo "INFO: Syncronize output directory to local output directory"
        rsync -av --delete -e ssh $dl_user@$dl_host:~/output/ ~/output/
        return 0
    fi

    # Monitor cluster usage
    if [[ "$do_monitor" = 1 ]]; then
        if [[ -z "$dl_user" ]] || [[ -z "$dl_host" ]]; then
            echo "ERROR: Some or all of the required parameters are empty"
            cluster_help
            return 1
        fi

        ssh $dl_user@$dl_host "sh /usr/local/bin/monitor-gpu"
        echo ""
        ssh $dl_user@$dl_host "sh /usr/local/bin/monitor-nodes"
        return 0
    fi
}
